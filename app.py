import gradio as gr
import subprocess
import configparser
import os, sys
import re

# å®šä¹‰ç•Œé¢
def infer(video_path, vocal_file, quality, wav2lip_version, use_previous_tracking_data, output_height, nosmooth, wav2lip_batch_size, padding_u, padding_d, padding_l, padding_r, mask_size, mask_feathering, mask_mouth_tracking, mask_debug_mask):
    # å†™å…¥é…ç½®æ–‡ä»¶
    config = configparser.ConfigParser()
    config.read('config.ini')
    config.set('OPTIONS', 'video_file', video_path)
    config.set('OPTIONS', 'vocal_file', vocal_file)
    config.set('OPTIONS', 'quality', quality)
    config.set('OPTIONS', 'wav2lip_version', wav2lip_version)
    config.set('OPTIONS', 'use_previous_tracking_data', use_previous_tracking_data)
    config.set('OPTIONS', 'output_height', output_height)
    config.set('OPTIONS', 'nosmooth', nosmooth)
    config.set('PADDING', 'u', str(padding_u))
    config.set('PADDING', 'd', str(padding_d))
    config.set('PADDING', 'l', str(padding_l))
    config.set('PADDING', 'r', str(padding_r))
    config.set('MASK', 'size', str(mask_size))
    config.set('MASK', 'feathering', str(mask_feathering))
    config.set('MASK', 'mouth_tracking', mask_mouth_tracking)
    config.set('MASK', 'debug_mask', mask_debug_mask)
    config.set('OTHER', 'wav2lip_batch_size', str(wav2lip_batch_size))
    
    with open('config.ini', 'w') as configfile:
        config.write(configfile)
    
    # æ‰§è¡Œå¤–éƒ¨è„šæœ¬
    python_executable = sys.executable
    result = subprocess.run([python_executable, "run.py"], stdout=subprocess.PIPE, text=True)
    
    # è¯»å–è„šæœ¬è¾“å‡º
    output = result.stdout
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–<video>æ ‡ç­¾çš„å†…å®¹
    match = re.search(r'<video>(.*?)</video>', output, re.DOTALL)
    if match:
        output_video_path = match.group(1)
    else:
        output_video_path = ""
        
    return output_video_path

# åˆ›å»ºGradioç•Œé¢
css = """footer {visibility: hidden}"""
app = gr.Blocks(title="Easy Wav2Lipæ•°å­—äººæ¨ç†", css=css, theme="Kasien/ali_theme_custom")

with app:
    gr.Markdown("# <center>ğŸ¡ - Easy Wav2Lipæ•°å­—äººæ¨ç†</center>")

    with gr.Tabs(elem_id="source_media"):
        with gr.TabItem('å‡†å¤‡ç´ æ'):
            with gr.Row():
                with gr.Column():
                    video_path = gr.Video(sources="upload", label="è§†é¢‘ç´ æ")
                with gr.Column():
                    vocal_file = gr.Audio(sources="upload", type="filepath", label="é©±åŠ¨éŸ³é¢‘")

    with gr.Tabs(elem_id="driven_audio"):
        with gr.TabItem('è®¾ç½®'):
            gr.Markdown("æ‰€æœ‰è§†é¢‘å¸§ä¸­å¿…é¡»éƒ½æœ‰ä¸€å¼ è„¸ï¼Œå¦åˆ™ Wav2Lip å°†æŠ¥é”™ã€‚ç¬¬ä¸€æ¬¡ä½¿ç”¨ï¼Œè¯·æµ‹è¯•éŸ³é¢‘è¾ƒçŸ­çš„æ–‡ä»¶ï¼Œå†è¿›è¡Œé•¿è§†é¢‘åˆ¶ä½œ")
            with gr.Row():
                with gr.Column():
                    quality = gr.Radio(choices=["Fast", "Improved", "Enhanced", "Experimental"], value="Enhanced", label="è§†é¢‘è´¨é‡é€‰é¡¹", info="ä¸è§†é¢‘ç”Ÿæˆé€Ÿåº¦å’Œæ¸…æ™°åº¦æœ‰å…³")
                    wav2lip_version = gr.Radio(choices=["Wav2Lip", "Wav2Lip_GAN"], value="Wav2Lip_GAN", label="Wav2Lipç‰ˆæœ¬é€‰é¡¹")

                    use_previous_tracking_data = gr.Radio(choices=["True", "False"], value="True", label="å¯ç”¨è¿½è¸ªæ—§æ•°æ®")

                    output_height = gr.Radio(choices=["full resolution", "half resolution"], value="full resolution", label="åˆ†è¾¨ç‡é€‰é¡¹é€‰é¡¹")

                    nosmooth = gr.Radio(choices=["True", "False"], value="True", label="å¯ç”¨è„¸éƒ¨å¹³æ»‘", info="é€‚ç”¨äºå¿«é€Ÿç§»åŠ¨çš„äººè„¸ï¼Œå¦‚æœè„¸éƒ¨è§’åº¦è¿‡å¤§å¯èƒ½ä¼šå¯¼è‡´ç”»é¢æŠ½æ")

                    wav2lip_batch_size = gr.Slider(minimum=1, maximum=128, step=1, value=1, label="æ‰¹é‡æ¨ç†batch_size", info="GPUèµ„æºå……è¶³å¯ä»¥è°ƒå¤§batch_size")

                with gr.Column():
                    padding_u = gr.Slider(minimum=-15, maximum=15, step=1, value=0, label="é¢éƒ¨è£åˆ‡åƒç´ -ä¸Š")
                    padding_d = gr.Slider(minimum=-15, maximum=15, step=1, value=0, label="é¢éƒ¨è£åˆ‡åƒç´ -ä¸‹")
                    padding_l = gr.Slider(minimum=-15, maximum=15, step=1, value=0, label="é¢éƒ¨è£åˆ‡åƒç´ -å·¦")
                    padding_r = gr.Slider(minimum=-15, maximum=15, step=1, value=0, label="é¢éƒ¨è£åˆ‡åƒç´ -å³")

                    mask_size = gr.Number(value="2.5", label="Maskå°ºå¯¸", info="å‡å°è„¸éƒ¨å‘¨å›´çš„è¾¹æ¡†")
                    mask_feathering = gr.Slider(minimum=1, maximum=3, step=1, value=2, label="Maskç¾½åŒ–", info="å‡è½»è„¸éƒ¨å‘¨å›´è¾¹æ¡†çš„æ¸…æ™°åº¦")

                    mask_mouth_tracking = gr.Radio(choices=["True", "False"], value="False", label="å¯ç”¨Maskå˜´éƒ¨è·Ÿè¸ª")
                    mask_debug_mask = gr.Radio(choices=["True", "False"], value="False",  label="å¯ç”¨Maskè°ƒè¯•")

                with gr.Column():
                    result = gr.Video(label="æ¨ç†ç»“æœ")
                    btn = gr.Button("ä¸€é”®æ¨ç†", variant="primary")
    
    btn.click(
        fn = infer,
        inputs = [video_path, vocal_file, quality, wav2lip_version, use_previous_tracking_data, output_height, nosmooth, wav2lip_batch_size, padding_u, padding_d, padding_l, padding_r, mask_size, mask_feathering, mask_mouth_tracking, mask_debug_mask],
        outputs = result
    )
    
app.launch(server_name='0.0.0.0')